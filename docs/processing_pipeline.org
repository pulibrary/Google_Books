* General Considerations
** Scale
GRIN says PUL has 277,970 books Google Books. Harvard says the default conversion rate (how many books GRIN can process into downloadable tarballs) is about 5,000 per day. Assuming we can download tarballs as fast as GRIN can put them up, that means a minimum of 56 days to process everything.

The size of the _converted pool at Google Books is also 5,000: once the pool size reaches 5000, older packages are replaced with new ones in the pool. 


* Harvard's Pipeline
Harvard implements a pipeline in a script called =liberate.py=. 

It assumes you have already:

- Downloaded a list of GB barcodes (using instadin's =grin.py= script)  (_all_files.tsv)
- Downloaded the latest MARCXML dump from Stanford's POD aggregator (latest was princeton-2023-02-10-full-marcxml.xml)
- Used process_pod_xml.py to match all the Google barcodes against POD records and augment them (records in grin_processed/pod_xml)

=Liberate.py= does much more than we want to do at the moment:
#+begin_quote
Processing does a few things:

1. Decrypt and unpack each `.tar.gz.gpg` archive
2. Extract and upload `LIBRARY_BARCODE.xml` (as `BARCODE.xml`)
3. Compile the page-by-page text OCR files into one .txt file, `BARCODE.txt` and as a tarball of each page as a single file, `BARCODE.txt.tar.gz`.  Both of these are uploaded to s3.
4. If POD XML file(s) exists within `--output_dir`'s `pod_xml` subdirectory, upload any matching files as `BARCODE.pod.xml`.
5. If a MODS XML file can be found in Harvards Library Cloud, upload that.
6. As data is collected and put into S3, a `.retrieval` sister file containing a timestamp is uploaded.
#+end_quote

* Another Approach
Rather than have a single, long-running process to do all the work, a more asynchronous approach would almost certainly be superior. One process manages the _all_books list: what books have been copied over to our bucket, what books should be queued up next, based on the state of the _converted pool.

Another process monitors the queue of books to be processed


** Tell Google to make a barcode ready for download
Use Harvard's grin.py script to do this:

#+begin_src sh
  $ python grin.py --directory=PRNC --method=POST --resource="_process?barcodes=123&barcodes=456&barcodes=789"
#+end_src
